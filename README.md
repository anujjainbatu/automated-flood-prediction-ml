# **Automated Flood Prediction ML**

This project aims to predict flood occurrences based on various weather parameters. It includes data fetching, model training, and prediction scripts.

---

## **Project Structure**

```
.DS_Store
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ FloodPrediction.csv
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ flood_prediction_model.pkl
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ flood_prediction.ipynb
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_fetcher.py
â”‚   â”œâ”€â”€ run_pipeline.py
â”œâ”€â”€ requirement.txt
```

### **Directory Breakdown**
- ğŸ“‚ **data/** - Contains the dataset used for training and prediction.
- ğŸ“‚ **models/** - Stores the trained machine learning model.
- ğŸ“‚ **notebooks/** - Includes Jupyter notebooks for data exploration and model training.
- ğŸ“‚ **scripts/** - Houses Python scripts for data fetching and running the prediction pipeline.
- ğŸ“„ **requirement.txt** - Lists the dependencies required for the project.

---

## **Setup**

### 1ï¸âƒ£ Clone the repository
```sh
git clone https://github.com/anujjainbatu/automated-flood-prediction-ml.git
```

### 2ï¸âƒ£ Create a virtual environment
```sh
python3 -m venv venv
source venv/bin/activate  # For macOS/Linux
venv\Scripts\activate    # For Windows
```

### 3ï¸âƒ£ Install dependencies
```sh
pip install -r requirement.txt
```

---

## **Usage**

### **ğŸ“¥ Data Fetching**
To fetch the latest weather data and update the database, run:
```sh
python scripts/data_fetcher.py
```

### **ğŸš€ Running the Prediction Pipeline**
To execute the entire prediction pipeline, including data fetching, model prediction, and saving predictions to the database, run:
```sh
python scripts/run_pipeline.py
```

### **â³ Automating with Cron Job**
To automate the prediction pipeline with a cron job, add the following line to your crontab (e.g., to run the script every day at midnight):
```sh
0 0 * * * /usr/bin/python3 /path/to/your/workspace/scripts/run_pipeline.py
```

---

## **ğŸ“œ License**
This project is licensed under the **MIT License**. See the LICENSE file for details.

